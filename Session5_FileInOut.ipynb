{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Chemists: File Input/Output Using Pandas and Plotting Using Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importance for scientists:**\n",
    "* The ability to read, manipulate and analyse data; one of the most important tasks for any scientist.\n",
    "\n",
    "As scientists, one of the key applications of programming is processing and analysing data. These data can arrive from a piece of lab equipment, a computer program, manually conducted experiment  etc... and there are a plethora of ways to read in data into Python, but the most important tool at the disposal of data scientists and analysts working in Python today is the [pandas](https://pandas.pydata.org/) library, making up the backbone of most projects involving data. \n",
    "\n",
    "* In this session we will cover the basics of the pandas library along with [matplotlib](https://matplotlib.org/) used to visualise data. \n",
    "\n",
    "* Pandas is a **very** extensive library and we will only have time for the fundamentals; but the [pandas documentation](https://pandas.pydata.org/docs/) is thorough, providing good descriptions of all features along with examples. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excel vs. Pandas\n",
    "* Conventionally Microsoft Excel is used for data processing and analysis due to its versatility, ease of use and reliability, but it has inherent limitations:\n",
    "\n",
    "    * It will slow down as the data sets become larger.\n",
    "    * Excel has a limit of 1,048,576 rows in a spreadsheet.\n",
    "    * It is harder to create and apply mathematical equations on the data. \n",
    "\n",
    "* Pandas is a solution which overcomes all these limitations:\n",
    "\n",
    "    * It is incredibly fast at processing very large volumes of data. You can apply hundreds of computations to millions of data points instantly using pandas.\n",
    "    * The only limitation on the amount of data is the computing power and memory of the computer it is running on. \n",
    "        * **If Public Health England had used pandas in place of their Excel spreadsheet they would have never lost 16000 COVID test results.**\n",
    "    * It can talk to fast numerical libraries such as numpy and scipy offering mathematical operations with the speed of the C programming language.\n",
    "    * It contains a machine learning backbone making it better at automatically reading and categorizing data. It can clean up data much easier than Excel and is capable of automating a lot of other processes including repairing data holes and eliminating duplicates.\n",
    "\n",
    "* Pandas is not necessarily a replacement for Excel, with both often being used together. \n",
    "    * You can start a project in Excel and port it over to pandas which can easily read Comma Separated Value files (`.csv`) files. \n",
    "    * For reference the name pandas is derived from the term \"panel data\", an econometrics term for data sets that include observations over multiple time periods for the same individuals. \n",
    "\n",
    "* As pandas is a separate Python library we have to import it in order to use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pandas deals with the following three data structures:\n",
    "\n",
    "| Data Structure | Dimensions      | Description                                        |\n",
    "|:---------------|:---------------:|:---------------------------------------------------|  \n",
    "| Series         | 1               | 1D labeled homogeneous array, size immutable.      |\n",
    "| DataFrame      | 2               | General 2D labeled, size-mutable tabular structure |\n",
    "| Panel          | 3               | General 3D labeled, size-mutable array.            |\n",
    "\n",
    "* All three data structures are **value** mutable (can be changed) and except Series all are size mutable. \n",
    "* Out of the three data structures **DataFrames** are the most widely used and important structures so will make up the entirety of this Pandas tutorial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "* A DataFrame is a two-dimensional array with heterogeneous data (data with high variability of data types and formats). Consider the following example:\n",
    "\n",
    "| Name  | Age   | Grade  |\n",
    "|:------|:-----:|:------:|  \n",
    "| Rob   | 27    |  A     |\n",
    "| Susan | 34    |  C     |\n",
    "| Jane  | 71    |  A     |\n",
    "| Tom   | 62    |  D     |\n",
    "| Brian | NaN   |  B     |\n",
    "\n",
    "* We can implement this in pandas using the following constructor:\n",
    "\n",
    "    `pd.DataFrame(data, index, columns, dtype)`\n",
    "\n",
    "* **data:** data takes various forms like `ndarray`, `series`, `map`, `lists`, `dict`, constants and also another DataFrame.\n",
    "* **index:** For the row labels, the Index to be used for the resulting frame is `np.arange(n)` if no index is passed.\n",
    "* **columns:** For column labels, the default syntax is  `np.arange(n)`. This is only true if no index is passed.\n",
    "* **dtype:** Data type of each column.\n",
    "\n",
    "* The acronym, NaN, is not a grandmother but stands for 'Not a Number' and pandas can easily handle missing data using numpy's `nan` command: `np.nan` or the \"None\" statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # numpy is needed for the nan entry\n",
    "\n",
    "# create a nested list containing our data\n",
    "data = [['Rob', 27, 'A'], \n",
    "        ['Susan', 34, 'C'], \n",
    "        ['Jane', 71, 'A'], \n",
    "        ['Tom', 62, 'D'],\n",
    "        ['Brian', np.nan, 'B']] # switch np.nan for None and check the output\n",
    "\n",
    "# call the DataFrame from the pandas library and assign names to each column\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age', 'Grade'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than spend days looking at all the pandas functions in a general overview, we will learn the important fundamentals by loading and analysing a real world data set reporting global climate change data between the years 1750 - 2015 taken from [Berkeley Earth](http://berkeleyearth.org/archive/data/). \n",
    "\n",
    "* The file is in a Comma-Separated Value format (.csv) which can be loaded using `pd.read_csv()`. \n",
    "* We are going to learn useful pandas commands applied to **real data** not small ideal examples from textbooks.  This file contains 9 data columns:\n",
    "\n",
    "    * **dt:** The date: year-month-day.\n",
    "    * **LandAverageTemperature:** The global temperatureaverage land temperature for that month, in celsius.\n",
    "    * **LandAverageTemperatureUncertainity:** The 95% confidence interval around the average value of the land temperature, in celsius.\n",
    "    * **LandMaxTemperature:** The maximum land temperature recorded for that month, in celsius.\n",
    "    * **LandMaxTemperatureUncertainty:** The 95% confidence interval around the maximum value of the land temperature, in celsius.\n",
    "    * **LandMinTemperature:** The minimum land temperature recorded in that month, in celsius.\n",
    "    * **LandMinTemperatureUncertainty:** The 95% confidence interval around the minimum value of the land temperature, in celsius.\n",
    "    * **LandAndOceanAverageTemperature:** The average temperature of the land and ocean, in celsius.\n",
    "    * **LandAndOceanAverageTemperatureUncertainty** The 95% confidence interval around the average value of the land and ocean temperatures, in celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/data/GlobalLandTemperatures_GlobalTemperatures.csv\"\n",
    "\n",
    "# read the data file using pd.read_csv()\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "# we tell the DataFrame that the 'dt' column is a date-time format. This is a smart command and will be able to understand a variety of date-time formats\n",
    "df['dt'] =  pd.to_datetime(df['dt'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Running this command loads the csv file and assigns it to the name `df` short for DataFrame. \n",
    "* Note that we have not asked it to print the data due to it containing > 3000 rows. \n",
    "    * Be careful when using the `print` command around large data sets as you can end up waiting for the processor to print out (possibly) billions of data values to the screen. \n",
    "    * Luckily pandas has a multitude of functions allowing us to view and manipulate the data without having to view it in its entirety. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing data is just as simple as reading in data, using the [`.to_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html) function. We can send our data set to a file of our choosing using the following syntax:\n",
    "\n",
    "    `name_of_dataframe.to_csv('name of file to save to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Cool_filename.csv\") # try other file types too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Pandas has a large number of functions for writing all manner of different file types.** See [this link](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html) for a summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Pandas functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>View information about the DataFrame using `info()`:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>View the top and bottom x-rows of the DataFrame using `.head` and `.tail`:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the top two rows\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the bottom two rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Display the index labels of each row using `.index`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>Display the labels of each column using `.columns`:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `describe` shows a statistical summary of the DataFrame including:\n",
    "    * **Count:** Number of rows.\n",
    "    * **mean:** The average of the data in each column.\n",
    "    * **std:** The standard deviation of each column.\n",
    "    * **min:** The minimum value in each column.\n",
    "    * **25%:** 25% of your data in the column is below this value\n",
    "    * **50%:** 50% of your data in the column is below this value\n",
    "    * **75%:** 75% of your data in the column is below this value\n",
    "    * **max:** The maximum value in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <font color='red'>Transpose data using `.T`:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sort values in specific columns using `.sort_values()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the LandAverageTemperature from lowest -> highest \n",
    "df.sort_values(by='LandAverageTemperature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A single column can be selected using the same syntax we previously used for dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LandAverageTemperature']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also slice our data like we did in the previous NumPy session:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice the DataFrame selecting the first 3 rows\n",
    "df[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Conditions on how data is selected can be applied. Consider selecting average land temperatures > 0 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['LandAverageTemperature'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lets extract data from the 1st January 1801 to the 1st May 2010; done using a `mask` which is a means of extracting data from a DataFrame given certain criteria:\n",
    "    * First we supply the conditions on the `dt` column that the dates we want are >= 1801-01-01 and <= 2010-05-01.\n",
    "    * We then pass these conditions to the DataFrame using `loc()` which allows us to access a group of rows or columns by labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the start and end date of our range\n",
    "start_date = '1801-01-01'\n",
    "end_date = '2010-05-01'\n",
    "\n",
    "# create the mask by selecting the 'dt' column from df, stating we want values >=start_date and <= end_date. & means and\n",
    "mask = (df['dt'] >= start_date) & (df['dt'] <= end_date)\n",
    "\n",
    "# apply the mask to the DataFrame\n",
    "df_range = df.loc[mask]\n",
    "\n",
    "print(df_range.head(5))\n",
    "\n",
    "print(df_range.tail(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We now have an idea of how pandas works, so lets now start visualising the data to really bring it to life; done using `matplotlib`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Data using Matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of Python's most popular functions is to visualise data, either to understand the data better, or to display the data to convey the results to someone else. \n",
    "\n",
    "* **Matplotlib**, arguably the most popular graphing and data visualization module for Python, allows for a very wide range of plots to be produced, quickly and easily. \n",
    "* The name derives from the fact matplotlib provides a MATLAB-like interface for plotting whilst being free and open source. \n",
    "* Start by importing the library along with numpy (just to make sure it is loaded!). \n",
    "    * We also load a sub module of matplotlib called `DateFormatter` which allows it to understand date formats correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Plotting two data columns in matplotlib can be done using the syntax: \n",
    "    `plt.plot(x data, y data)`. \n",
    "* Lets plot the average temperature vs. the date: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the date column from the DataFrame as the x-data\n",
    "x_dat = df['dt']\n",
    "# assign the average land temperature from the DataFrame as the y-data\n",
    "y_dat = df['LandAverageTemperature']\n",
    "\n",
    "# plot the data\n",
    "plt.plot(x_dat, y_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can do better than this:\n",
    "\n",
    "    * There is too much data for one plot and does it show us anything?\n",
    "    * Axis labels\n",
    "    * Title\n",
    "    * etc...\n",
    "\n",
    "* A useful plot will be the average temperature **each year** not every month of each year, which we can do by:\n",
    "\n",
    "    * Using the pandas `dt` accessor to access the years in the date-time column 'dt'.\n",
    "    * Group the data into years by passing it the year numbers we just calculated, and calculate the mean on the 'LandAverageTemperature' column aggregating as a new column using the `.agg()` command which allows us to apply specific functions to specific columns. In this case we want to calculate the `mean` of the temperatures of each year using `.agg(['mean'])`.\n",
    "    * Assign this to a new DataFrame and then plot it.\n",
    "\n",
    "* We will use some very important matplotlib commands:\n",
    "\n",
    "    * `fig, ax = plt.subplots()`: A function that returns a tuple containing a figure (fig) and axes (ax) object(s). \n",
    "        * We call this before we begin any plotting as it returns two objects: \n",
    "            * One for changing figure-level attributes (fig). \n",
    "            * One for everything else (ax). Axes define a subplot, we can write our own x-axis limits, y-axis limits, their labels, the type of graph. It controls every detail inside the subplot.\n",
    "    * `ax.set_xlabel()` and `.set_ylabel()`: Used to set axis labels.\n",
    "    * `ax.set_title()`: Used to set the figure title.\n",
    "    * `plt.show()`: Prints the plot to the screen. Notice above how we did not use this and it still showed the graph? This is a feature of the Jupyter notebook, but when running locally you need to use `plt.show()` to print the graph to screen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure (fig) and axes (ax) objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# first we extract the years from YYYY-MM-DD format\n",
    "# we call the .dt command from the DateFormatter library and ask it to extract the .year from all the dates\n",
    "# mask becomes a pandas series which holds the years for us \n",
    "mask = df['dt'].dt.year\n",
    "\n",
    "# apply the mask to the DataFrame and assign to a new DataFrame\n",
    "# we use `.reset_index() at the end of the line as when we apply the groupby and agg commands the new DataFrame loses access to the column names \n",
    "# This means we have to reset the indexing to remind it what they are!\n",
    "df_avg_yearly_temp = df.groupby(mask)['LandAverageTemperature'].agg(['mean']).reset_index()\n",
    "\n",
    "# x-data is the year column and y-data is the mean column\n",
    "x_dat = df_avg_yearly_temp['dt']\n",
    "y_dat = df_avg_yearly_temp['mean']\n",
    "\n",
    "# plot the data\n",
    "ax.plot(x_dat,y_dat)\n",
    "\n",
    "# add the axis labels using set_xlabel and set_ylabel\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Average temperature / $^\\circ$C') # LaTeX syntax is also recognised. Do not worry if you have not heard of LaTeX, it is not important here\n",
    "\n",
    "# set title using set_title\n",
    "ax.set_title('Average yearly temperature')\n",
    "\n",
    "# print the plot to screen\n",
    "plt.show()\n",
    "\n",
    "# if you want to save your figure, you can use the command plt.savefig('name of file')\n",
    "# plt.savefig('name of file.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This plot is better than our previous attempt; showing a much clearer upward trend in average yearly temperatures as time passes. \n",
    "    * What about the maximum and minimum temperatures? We can follow the above procedure and plot these two data sets with our average yearly temperature data on the same graph. \n",
    "\n",
    "* We will assign labels to each of our plots within the plot command:\n",
    "\n",
    "    `.plot(x data,y data, label=\"legend label\")`,\n",
    "\n",
    "* and by calling `ax.legend()` it will automatically construct the legend for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure (fig) and axes (ax) objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# first we extract the years from YYYY-MM-DD format\n",
    "mask = df['dt'].dt.year\n",
    "\n",
    "# group the maximum temperature data by year and take the average\n",
    "df_max_yearly_temp = df.groupby(mask)['LandMaxTemperature'].agg(['mean']).reset_index()\n",
    "# group the minimum temperature data by year and take the average\n",
    "df_min_yearly_temp = df.groupby(mask)['LandMinTemperature'].agg(['mean']).reset_index()\n",
    "\n",
    "# assign x and y-data for max temperature\n",
    "x_max_dat = df_max_yearly_temp['dt']\n",
    "y_max_dat = df_max_yearly_temp['mean']\n",
    "\n",
    "# assign x and y-data for min temperature\n",
    "x_min_dat = df_min_yearly_temp['dt']\n",
    "y_min_dat = df_min_yearly_temp['mean']\n",
    "\n",
    "# plot the average max temperature data\n",
    "ax.plot(x_max_dat,y_max_dat, label=\"Avg Max temp\")\n",
    "\n",
    "# plot the average temperature data\n",
    "ax.plot(x_dat,y_dat, label=\"Avg temp\") \n",
    "\n",
    "# plot the average min temperature data\n",
    "ax.plot(x_min_dat,y_min_dat, label=\"Avg Min temp\")\n",
    "\n",
    "# add the axis labels using set_xlabel and set_ylabel\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Average temperature / $^\\circ$C') # LaTeX syntax is also recognised. Do not worry if you have not heard of LaTeX, it is not important here\n",
    "\n",
    "# set title using set_title\n",
    "ax.set_title('Average maximum and minimum temperature')\n",
    "\n",
    "# call the legend command which will construct the legend using the labels we applied to each of our plots and automatically change the colours\n",
    "ax.legend()\n",
    "\n",
    "# print the plot to screen\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As there is no maximum and minimum temperature data before the year ~ 1850, <font color='red'>we will now specify the range of the plot to remove the whitespace on the left of the Max and Min temperature plots using `axes.set_xlim([xmin,xmax])` in the above code block</font>\n",
    "\n",
    "* The legend appears to have a mind of its own sometimes but we can control it using the `loc=` argument inside legend():\n",
    "    * best\n",
    "    * upper right\n",
    "    * upper left\n",
    "    * lower left\n",
    "    * lower right\n",
    "    * right\n",
    "    * center left\n",
    "    * center right\n",
    "    * lower center\n",
    "    * upper center\n",
    "    * center\n",
    "    * or using coordinates! loc=(x_coord, y_coord)\n",
    "    \n",
    "    `ax.legend(loc=(1.05,0.8))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we return to the plot of *just* the average yearly temperature. \n",
    "    * We have the 95% confidence interval of the average temperature so lets add this to the plot (assuming the confidence interval is symmetric about the mean) and show how the error in temperature measurement changes with time. We will plot the confidence interval as a shaded area around the data set using:\n",
    "\n",
    "    `plt.fillbetween(x data, ydata - CI, ydata + CI, alpha=x)` \n",
    "\n",
    "* where:\n",
    "\n",
    "    * `CI` is the confidence interval value.\n",
    "    * `alpha=x` is the transparency of the shaded area in the range [0,1] where x=0 is transparent and x=1 is opaque. Any floating point number in this range is acceptable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create the figure (fig) and axes (ax) objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# first we extract the years from YYYY-MM-DD format\n",
    "mask = df['dt'].dt.year\n",
    "\n",
    "# apply the mask to the average yearly temperature and its uncertainty\n",
    "df_avg_yearly_temp = df.groupby(mask)['LandAverageTemperature'].agg(['mean']).reset_index()\n",
    "df_avg_yearly_temp_uncert = df.groupby(mask)['LandAverageTemperatureUncertainty'].agg(['mean']).reset_index()\n",
    "\n",
    "# x-data is the year column and y-data is the mean column\n",
    "x_dat = df_avg_yearly_temp['dt']\n",
    "y_dat = df_avg_yearly_temp['mean']\n",
    "\n",
    "# uncertainty data\n",
    "x_uncer_dat = df_avg_yearly_temp_uncert['dt']\n",
    "y_uncer_dat = df_avg_yearly_temp_uncert['mean']\n",
    "\n",
    "# plot the data\n",
    "ax.plot(x_dat,y_dat)\n",
    "\n",
    "# plot the CI as a filled area around the data points\n",
    "ax.fill_between(x_dat, y_dat-y_uncer_dat, y_dat+y_uncer_dat , alpha=0.2)\n",
    "\n",
    "# add the axis labels using set_xlabel and set_ylabel\n",
    "ax.set_xlabel('Year')\n",
    "ax.set_ylabel('Average temperature / $^\\circ$C')\n",
    "\n",
    "# set title using set_title\n",
    "ax.set_title('Average yearly temperature')\n",
    "\n",
    "# set the range of the x-axis data\n",
    "ax.set_xlim([1750, 2015])\n",
    "\n",
    "# print the plot to screen\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This plot shows us that the confidence interval was very large for years before 1875 but is much smaller afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Examples\n",
    "\n",
    "matplotlib is able to plot a **huge variety** of different plot types. The following link has hundreds of different examples with source code and output for you to practice and see what it is capable of:\n",
    "\n",
    "* [matplotlib examples](https://matplotlib.org/3.1.1/gallery/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure (fig) and axes (ax) objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# create x range from 0 -> 2Pi with a step of 0.1\n",
    "x = np.arange(0, 2*np.pi, 0.1)   # start, stop, step\n",
    "\n",
    "y1 = np.cos(x)\n",
    "y2 = np.sin(x)\n",
    "\n",
    "plt.plot(x, y1, label = 'cos')\n",
    "plt.plot(x, y2, label = 'sin')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Line Styles and Colours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom line styles can be specified by adding the following to your plot command::\n",
    "* `'-'` : Solid line.\n",
    "* `'--'`: Dashed line.\n",
    "* `':'` : Dotted line.\n",
    "* `':.'`: Dot-dashed line.\n",
    "\n",
    "Custom line styles can also be specified but we will not cover that here. Colours can be specified by adding `color = ` to your plotting command. Note the spelling of color! There is a [large variety of possible colours](https://matplotlib.org/3.1.0/gallery/color/named_colors.html) but it is also possible to specifiy colours using RGB values which means any colour can be used. \n",
    "\n",
    "Consider the plot of cos(x) and sin(x) this time using custom colours and line styles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure (fig) and axes (ax) objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# create x range from 0 -> 2Pi with a step of 0.1\n",
    "x = np.arange(0, 2*np.pi, 0.1)   # start, stop, step\n",
    "\n",
    "y1 = np.cos(x)\n",
    "y2 = np.sin(x)\n",
    "\n",
    "plt.plot(x, y1, ':', color = 'orange' ,label = 'cos')\n",
    "plt.plot(x, y2, '--', color = 'blue' ,label = 'sin')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markers\n",
    "\n",
    "There are a [wide variety](https://matplotlib.org/api/markers_api.html) of data markers available with a selection printed below:\n",
    "<center><img src=\"https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/images/matplotlib_markers.png\" width=\"600\" height=\"600\" /></center>\n",
    "\n",
    "* Consider the plot of cos(x) and sin(x) this time using custom colours and colours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the figure (fig) and axes (ax) objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# create x range from 0 -> 2Pi with a step of 0.1\n",
    "x = np.arange(0, 2*np.pi, 0.1)   # start, stop, step\n",
    "\n",
    "y1 = np.cos(x)\n",
    "y2 = np.sin(x)\n",
    "\n",
    "plt.plot(x, y1, 'd', color = 'orange', markersize=4, label = 'cos')\n",
    "plt.plot(x, y2, '.', color = 'blue' , markersize=4, label = 'sin')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we covered:\n",
    "\n",
    "* what pandas is and the key differences it has compared to Excel.\n",
    "* What Series, DataFrames and Panels are, the three main pandas object types.\n",
    "* How to manually build a DataFrame.\n",
    "* How to read data into Python using pandas.\n",
    "* How to manipulate and access the data using pandas.\n",
    "* How to plot data from a DataFrame using matplotlib and the key matplotlib commands.\n",
    "* How to apply masks to your data to access specific information and then plot it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "* In one of the above examples used a mask to plot only the yearly temperatures.\n",
    "\n",
    "* Following the same idea mask for the months of July and December and then compare monthly temperatures across all the years. \n",
    "    * Plot the the average land temperatures in July and December:\n",
    "* The following code is almost complete but contains several errors so will not run. Read through the code, fix the errors and produce the plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_url = \"https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/data/GlobalLandTemperatures_GlobalTemperatures.csv\"\n",
    "\n",
    "# read the data file using pd.read_csv()\n",
    "df = pd.read_csv(data_url)\n",
    "\n",
    "# we tell the DataFrame that the 'dt' column is a date-time format. This is a smart command and will be able to understand a variety of date-time formats\n",
    "df['dt'] =  pd.to_datetime(df['dt')\n",
    "# create the figure (fig) and axes (ax) objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# first we extract the months from YYYY-MM-DD format\n",
    "mask = df['dt'].dt.month\n",
    "\n",
    "jul_mask = df['dt'].dt.month == \n",
    "dec_mask = df['dt'].dt.month == 12\n",
    "\n",
    "df_jul_temp = df[jul_mask]['LandAverageTemperature']\n",
    "df_dec_temp = df[dec_mask]['']\n",
    "\n",
    "# x-data is the year column and\n",
    "x_dat = df[jul_mask]['dt'].dt.year\n",
    "\n",
    "ax.plot(x_dat, df_jul_temp, label=\"July\", color='orange')\n",
    "ax.plot(x_dat, df_dec_temp, label=\"\", color='blue')\n",
    "\n",
    "# add the axis labels using set_xlabel and set_ylabel\n",
    "ax.set_xlabel(')\n",
    "ax.set_ylabel('Average Temperature / $^\\circ$C')\n",
    "\n",
    "# set the range of the x-axis data\n",
    "ax.set_xlim([1750, 2015])\n",
    "\n",
    "# set title using set_title\n",
    "ax.set_title('July/November temperature from 1750 -> 2015')\n",
    "\n",
    "ax.legend()\n",
    "# print the plot to screen\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
