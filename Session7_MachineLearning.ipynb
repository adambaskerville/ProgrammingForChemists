{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming for Chemists: How Machine Learning is Changing Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning, the buzzphrase of the last 5 years but what is it? why is it important? why is there a session dedicated to it? Is it just applied statistics? We are going to:\n",
    "\n",
    "* Find out what machine learning is and why it is important for scientists.\n",
    "* Tools needed to do it.\n",
    "* How it is used in science.\n",
    "* Find out many of you have done machine learning without realising it.\n",
    "* Predict the solubility of small drug molecules using machine learning.\n",
    "\n",
    "**Aim of this session:**\n",
    "\n",
    "Machine learning is a **vast** and **rapidly** growing field of research built on complex mathematics and statistics; which we will **not** cover. Instead we are going to explore how you can **use** it to solve real world problems; application over theory. There is a high probability you will end up using some form of machine learning in your future career, so it is more important you understand how you can use it as opposed to spending months or years understanding the mathematics behind the algorithms. [The following image](vas3k.com) gives a bird's-eye view of the machine learning world:\n",
    "\n",
    "<center><img src=\"https://i.pinimg.com/736x/05/38/08/0538088de4041bda05c6f1febc99e1bb.jpg\" width=\"600\" height=\"600\" /></center>\n",
    "\n",
    "We already benefit from machine learning in our day to day lives:\n",
    "\n",
    "* **Image recognition**: Software trained using ML to scan through hundreds of MRI and CT medical images per second highlighting abnormalities. Computers have long exceeded the accuracy of a human in this field.\n",
    "* **Medical diagnosis**: Training programs using clinical symptoms to accurately diagnose patients. \n",
    "* **Speech recognition**: ML is behind the rise of assistant software like Alexa and Siri. \n",
    "* **Google**: Google is at the forefront, investing huge amounts of money into all facets of ML. It is used in their translation software, Google photos, Google assistant, Google Maps, self driving cars and many more.\n",
    "* **Financial services**: Used extensively in the finance sector to predict market shifts, customer spending patterns and it can even predict account closures before they occur!\n",
    "\n",
    "**Philosophy of AI:**\n",
    "\n",
    "Artificial Intelligence is a hotly debated issue in computer science and wider society for good reason; it could be humanities greatest invention but could it be our last? My personal take is more optimistic believing that AI systems capable of learning will only enhance and improve our own capability of learning. If I am wrong, at least this session will give an insight into how the machine overlords will *think*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Artificial Intelligence, Machine Learning, and Deep Learning. What's the Difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/images/AI_ML_DL.jpeg\" width=\"400\" height=\"400\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no agreed upon, standard definitions for any of these subject fields, but the [Google Machine Learning glossary](https://developers.google.com/machine-learning/glossary#m) provides sensible definitions:\n",
    "\n",
    "**Artificial Intelligence (AI):** A non-human program or model that can solve sophisticated tasks. For example, a program or model that translates text or a program or model that identifies diseases from radiologic images both exhibit artificial intelligence. Formally, machine learning is a sub-field of artificial intelligence. However, in recent years, some organizations have begun using the terms artificial intelligence and machine learning interchangeably.\n",
    "\n",
    "**Machine Learning (ML):** A program or system that builds (trains) a predictive model from input data. The system uses the learned model to make useful predictions from new (never-before-seen) data drawn from the same distribution as the one used to train the model. Machine learning also refers to the field of study concerned with these programs or systems.\n",
    "\n",
    "**Deep Learning (DL):** Is a machine learning technique that constructs artificial neural networks to mimic the structure and function of the human brain.\n",
    "\n",
    "Machine learning exists at the intersection of computer science, statistics, and data science. It uses elements of each of these fields, processing data in a way that can detect and learn from patterns, predict future activity, or make decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Barrier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With so many companies wanting to use machine learning, its implementation has become quite high level requiring small amounts of code; the biggest hurdle being the cost of the hardware to calculate in sensible time.\n",
    "\n",
    "AI, ML and DL are mainly based on learning from **very large quantities of data** which standard computational hardware struggles with. To achieve results within a sensible time frame you often need server racks full of Graphical Processing Units (GPUs) to run everything using massively parallel programming. The popularity of video gaming has been the dominant force in the development of faster and bigger GPU technology which has allowed AI, ML and DL to expand so quickly. For companies wanting to analyse large volumes of data the bill can be hundreds of thousands of pounds on hardware/software alone plus the power and expertise to run it.\n",
    "\n",
    "**Difference between a CPU and GPU?**\n",
    "\n",
    "This is a technical topic but NVIDIA hired the Mythbusters to explain the difference more practically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wCEABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2MBERISGBUYLxoaL2NCOEJjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY//AABEIAWgB4AMBIgACEQEDEQH/xAAbAAEAAwEBAQEAAAAAAAAAAAAAAQIDBAUGB//EAEsQAAIBAgQDBQIJCAcHBQEAAAABAgMRBBIhMRNBUQUUImFxgZEyM1KSobHB0eEVI0JTctLT8AYWQ2KCk/EkNGPCw+LjVHOio7JE/8QAGAEBAQEBAQAAAAAAAAAAAAAAAAECAwT/xAAkEQEBAQADAAICAwADAQAAAAAAARECEiExQQMTMlFhQnGBIv/aAAwDAQACEQMRAD8A/PwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAacGXVDgy6oYMwacGXVDhS6oYMwacKXVDhS6oYMwacKXVDhS6oYMwacKXVDhS6ouDMGnCl1RHCl1QwUBdU2+aHDfkTBQF+FLqhwpdUXBQF+G/IcN+QwUBfhS6ocKXVDBQGnCl1Q4MuqGDMGnBl1Rbu0+sRgxBt3afWJbulS2jj7xia5wb91n1iR3afWIw1iDbu0+sSO7z6xGGsga8CXVEcGXVDF1mC/Cl1Q4b8iYKAvwpeRPBl1RcGYNOBLqie7y6xGGsgbd3n1iO7T6xGJrEGvd59YjgS6oYusgacGXVEcKXVDBQF+FLyHCl1RMFAacKXVDgy6ouDMGvAl1Q4EusRgyBrwJdUOBLqhgyBrwJdURwZdUTBmDTgy6ocGXVAZg04MuqHBl1QGYNODLqhwZdUBuAuQNohgEhDkQSQFCCQEQCUQFCGSRIAiCYjmABICDRFiUSBCJQRKAixKJauQtwLWLxlbcpG6Lq0vUCzV9SNUQrplrp7oqF0yGHG22xFwIuQyWVZBBBIAq0VsXZVhUIsiESBYlFSyYFkTcrcXCJZDAAq0VaNLFWFUJsAAJBKAIDmABKIJAMqWZVkAEEhQAACGSQ9gJ5AElRBBIAgAAACAAJQAgiRJWQExBCJAkkhFgIFgSgFgSLAES0ESBCLLzGUFRLBK2HoA9GQGQBBD1LPUqAIJBBVlS9ioVAJAAm5BIEgglAWQACBVliAKgmxDCiLEIlAQQSyABYqiQDKi5BFSSVuSBYgACA9gQ9gLsPQjoSyogMMAQtwySGAIZJAEgEIAVZZ7EMBEkRFtQCLIjmWsBDJWhO5FtvMIsyPIlbC3MogsnchrUm3NAW2IkrallqgujArGWomrahxaZMHdWYEfCRG2hLThK5M1e0lzAq1daBau3UQeonHLYCuzBeorpTXMqtdAIaKs0t4X5GctGAa0KmlvC/IrbQioAirky0YDkSirLLRAWCIRIQAAEMhIncBUAkgCASQBKIexKIkBDIJIIoAQBa5FyABKHIgcgNOgY5IcyolK7sVZKbTvcjmBayy87lUrstKV0kISyST6AVkrOxBLd3cLzAgDmTyAhlWW5kMCYrQczSDiqbTTuVe4Ecy+nQh7I2pUeJTclJXi1p5df56lRmulhZW8yWtibcwIVlJX2LNIq14S26TAjRq3MLSWuwtqmS1dXAfBZL1V0F4lZkJtMCXaUSklld+Re2V3W3MLfK9nsBC8a8yqeW6ew1py8iZeNX5gVcbPyZd+KC0Kp3i4y9hNOVnaW19QENU4N+hRbmk1kkpRknZ20+spK17oCy0bM5I0Uo+Fu/R+hWaT2AL4DKPSJaDInqBEdNSHuXtt0KvcghasknZeZCQVIDCAkhgBDYAXCjIZJDAgAICSGCCCAAwqAAAIJIIBJAKNeSJHJAqIsLDkGBAAAgEkACSCUAsQWRHMCYol76CPQmSyuz3KG6L0pZXrsVkrMm2gRd2af0C2id9+RF9Sbt2AhrR2EdidHfyQ2iwItdMlDmiX5cgItb0D1336ku2r6EPUCE9Ndxyt7mNwvwAhu61KrTQtJW195DS3uBD115i9xYATcjn5C2rHK4EdQ27LqTuiLaANnfkCbaBqyQCVtLdCqLWDQFGSCbO9rAQhcAgAnmAIAAUIZLIAgAMAVJIIqAAAAAEAAggAAb7pAlLREM0hYWJYArYWJACEYu+aTj6K5tHDQkrqo7fsfiYxOmj8Wiiqwsf1r+b+JKwkP1r+Z+JqSEZd0h+tfzPxHc4XvxX8z8TYkDLgU6a8U7r9n8TCUad/hy+b+J1yajFuSuuhxvTUCu5JHIlbAXirk2IS1L3dgK7J+ZDd1axbd+wiW7AJk+wiGupdq0EBS3kFdCWxLWgFXvdEM0tt6lbb+oEX021K7KxZq1/UlR39LgZsgs0EgIuQS+ZADUAAPInfcWJ5ACCSOYEPckWAEDY7KXBwtKNWrTVavLWNKV8sV1l1vyXv6Ewx2Z2r4ehUpveMaUYNejik0BxA2xVKNHETpwnngn4ZdU9V9BiQQCQBDIJIYVBDJZDAggkEVBBJDAC5AAkgAAQSQQdaWiKvc0taKKNGkQiSIk3S3Ah6EEuSZD0XmBKOmj8UvU5zoofF+0qJZIe4AImwQsETUX5l38jllF2vy9Tpq6UG/JHG5OTu7ewKNhMgmGrA1UlFvwp+ptaLgm8ivpaNzKCTlrtuyyyuy1XLcCJWTskUe5pOKSbXLT1KTVkvQDr7LhTqYhxqwUllb1fp5r6z36GFwGmbD0n6q/11TwuyP8AeJWjJyy8r7XXRPyPXcJq14z9z/cNfTNejCh2R/aYKD9Ix/fNadLsZLw4H/4xf/MeI1K78Mvm/wDjJp0Zz1UGl/7bf/SBle9H8lRd1g5L0pr94irLs2Ti+7VbZtVw/wDuPElQmldw0X/Cf20jKUEl8C3+FfwwPaliOzOHJ0sG80ZNPNSuufSWhxflGnFzj3PDSVmk1SSy+ump4UqqjiKkbRSvJO6j1/ZVuXQ14kZyco6p/X7LdUd/x8ZnrHL/AB7C7Rw9XDZauHowvpdQpv6MvlzPMxVGhKydKnaK0nTjldvNXtcxc27rM9NWn7vtNlRlBRVSMrauEuT05G7w4/S8eX9vOxWDlSd4PPFpeq0OTY9iSlS8aWejFpStyXVdP56nJXw8autK2datdfM4cuHvny6Z5s9jiBZwlFuM4tNdSEtzkJirq5JMErE6AZshEtWbJhCUm8qvZXAlItRpOtXp0k7OclFP1dj0cH2bTrtQqYnLNtRjGnDPe/tR73ZOB7OwdTOr16kJfG1KW+1nFN6etn68gmvEo4R47tGviJ0ak8NCcnaKazRWkYp+7ToimI7NxVLF8Wjg6qjmU40+HJ2XL2H0/broYrBKNGnWlXVrOUrpa6nz3csV+qmXDVcR2T2nXlJ91VpO6vKCf13Mv6u9p/8Ap1/mw+827niv1Uys8HjtqdF+rdhhqn9XO0rfFU/86H3kT/o72lCTToxdulSOv0l44THwi3Ogn6TN3Qxc8Dh3Ok88ZTho7+HwyX0ykMg5P6vdpWvwY/5kfvKv+j/aH6qH+ZH7zZ4fE/q6nuKvD4n9XU9w8PXPPsXGU9ZqlH1qxX2mFXs+rSXjnQXkqsW/oZ7vZ3ZtBqNfFUnKpfTM2rWPQq4TBwjLEcGnKUcsU56+fP0L107PiJRcXaSsyh9u44KvhqnEw1C8UrLIuvI+Y7VwUMPNVKPxcna3yWZvFZdeeVZLBlpAJIYAEkAQACDsXwSrJj8Eh6GkU2YHMlAIq2o3kQ2THcCx00Pi/acx00fi/aWIl/CJY/SDCCJAAiv/ALvL0OJHdW/3eXocS2CxBMd7EPYmO4HTFqF3rqVjGThJ3SSe1yJXuoL2CSlBq6ad+YEzk5NXbM5O7LK7TZWPMDt7KyvESUkmsr3SfTqmevlprlTXzPuPH7Klau3e3hfO32r6z2eJ4dJ//Z/3mozWDlSu7ulv1h95vRqUVD+xv58L7WYqcuU5f5j/AIhvSrSjG3Gqr0nP+KBNSrSyys6C0/4X2TOaVWL2lT+dH+Idsq85Qa49d35Zqj/6jMZupbWdV683U+9geJVm+8VMsr+KW1mv/wBMlzgrppKWt7O1veMRFvFVk3Vtnet5dfaZzheV3Wk2+cjtxvjNdEM1RxjOpC2tnPw/T/O569OXEwboKpGU2vC7vTmt7HgwpybWWUE2t1JJ/Q9y6qThJT8N9MrTX+peXpLj2MFQaw854iLlJSyKmt/O7MMbTw8J0ZUqeWMKilKLeuW+quVjjak6SlGoryWqa9n8+h52KrzTvJ30scOX5OVuV248cmx9f2dhsH2lRqyp4DDuNOylKrWlZ/X0NJ9n4XDJx/JeFlGO7zOX1q5832N2xHC4SdKUoxfFzpv0t956S7eoXalW5WtF6Wsk7dL2/wBDPLla48tl8b18X2dhZxhPsrCt2volt7vI8dYrjdprh4fDqm614UuDTUXG/wAG9vNc9rnJ2rjIVsWqlJrLkSsne2rOSVZqqtUlkVvoJLs9a4y56+h7RwWIxVWLpdn4ajFRkrUqlON29m7PWx51fs6OHqOE2+L8KWSV4QUkmo35uzOBYmptf6TSrWjVrSnnabcdUttFd/z0Lrcnj1+zMHL46MZfAqKm3y8Ds/fY3ji7TcXK7Wm/Q86PaNWngYqj8JJLMnqjijSqWzym099C7Ik42vo++L2k98R4UKrjKT+VZ7+RfvD/AJZezPV7HfB3xdEeM8Q/5ZV4l9PpGmPa74rrRF6WLj3JaLSdvo/A8HvL6fSawxH+wz8qsF74z+4aY9XvkeiKvGR+SjxniX0+kjvDGrj2pY85q+Mzq1zzXiGYVKzvoTsdXqce0W7nPiZqpQnGWqtf3HNDEJRd4qSa2bsaYau60oUfgybtFrWzfVProTTHnVKThGMntO9jM6ZN1cJKcldwnFJpW0ad/qRzGW0AACS8aTccz0iRKLp2T3tctTl+bnpdsDN2uMry5uQcXvyIRFdUdis3yJbskVs2zTKLEth+mhUCS0dilzRfBQEnRR+Lfqc5vR+LfqVF38JjmObI5gWAAQq/ES9DivodtT4iXoceV8wqjLR3I5kx3A3s3Jyy6EdW97kt6SeUZW3GNrPncCtvC9CqNHd00kt2Z+lgO3si6xTy3vke1/Loz2nnttU90/xPE7MWbFNWu8vyb8/2X9R7FSnFx1gvm/8AYaSs3xLvwVHr0n+6E6t7ZJ/Nl/DKKlBX8MN+cI/uGlOnStdql7VD9wCctR7wl7Yf+IpUpSS1pr5i/hG2XDqL1orTrT+5GNSdJR8Mqfzqf7wHlV45cTUtBXzvmlz/AGUFd6ul4WtZSn0GIlHvNR5VNZ5aRaatfykzJSS1pwtp+jL7Dpx58cxb+PlfZGlSVKc26dNRW9lJ29gjOMdHCLSf6KXTq/YZ18S5rNw7JXVtLL8NdzlnWlNXb303dy38nFP18nZUxWWKh4Xlurx+85quInV0k0o/JRg3oVucLdut/HjWMJSdoxcn0Suayw9WmpOdKrHpmhY07Lf+0v8AYf1o6cZXVOrdpu/3HO33GLbuOeOEm6MajnSV/wBFvxe5bCFFSU3UlKKUfCkr3a666IzeJbbaVrm0HKdOTb0yjanrnsiybStyKw1nZtJWer9D2v6M9lU+08ZKVdN0KVsyTtmb2Xpo37Do05ezqeIxdfgUaU6rqPWyvlvzfRH0Vf8AopiIUXlrRcrbWPoaEqWGo8PD0oUoLaMFZErEybSb8ka6z7Jys+H53XoVcPPJWpypy6SVjK5+hYtU62WjXjCcZPaSTPhu38JHA4iM8PrRqbc7NbolmDkZVnM68jSKqTtZPXnYyrQ2oPNhcTTtd2jUX+F2+qTOSUasb3hJJbuxphqvDrRnlc4rScUt4vR/QBDIuXr4erRrumk5R3U7aOO+b3GNW0ZWjJTStdrq0BZspLYrNuHmdNKlh8y42JyrfwwciBgsNPETaWkUtZPZHX/sGHk3T49RpZZVItNRvpe2h30sDhsfhODhMU6Uo3SU0vFd31+q/Q+fr0a+CxMqdS8Kkeae/mn0LifLftCjLDwhBzjONR54OOkcttLdN2cB6Ck6/ZVRTblKjLMm+jsrfS37DzyNAs97Ex30OyNRqEkqqUJwWaPW1tPevoM241x4643mk23diMbPcm7XPcrcqJd+pGwuANlruS2ReyRFzTKb3ja+i8iG1yRMXZ3KgEaGcdZGgEm9H4t+pgb0fi36lRbmOY5gCQAETV+JkvI429LHXUdqTfkcTl5IKWLU05Oy6XIvdXZNLR3A14jXhje909+ZCctvaUTu2y9JpKo5K/hstdndfiBbRNZ0/ROxSacEm1a5rh3TzxdSN0m7+hlWkqlXwxUUlZIDq7Ls8XeSVsr3t9p7FSVOK3gk/OC+1Hkdm+HErXL4Xzt9q+s9mbk7WqS9kn9kzUSufiR5Sj85fxDSFTT4xfPX8VB8S7tKp75/eTGVZaXq+6YGiqTs7VZbcqj/AIxWTm4/CqPVfpSf/Oyc9ZprLVat8mf7hWopuOtKa9Yv+EB42Nv3yq5cReN+LM9NfVlE3OKSs6j2f3+fmXxaisXVzqzzO2m2v7KMb6JqV7crfBON+Xu/H/F04elGtiOFWpTa5tOzj5+wjF9n0KKm6dZ1LK8Fly5vP6GKdZxp2jUUvJPb+ftM+O7+NZtLaMmry43lXmSbbBvitXGSTWltUYWNx5eXHrcdfZrtiH+y/sNe0fhxfr9hn2e1xJxd7taM9/sutgqXFeNpqo3bLGVJTXPzRnN5OV/k+YR6cYZcIvOF/oPWWJwNSrnfZ+GyLMrRjo1fR77+3qcrx2GniabeFo0qCzxcFmk2lazt/PM3y46l9eItmfZf0cSodiRlBuM6s5Sl9St7jwMXPC1KsFQoqEWmk4q3ivpffTY+hwSpYTAU6Lrx4ijfK5KWW7b3W9rmo09VSz0IzX6STsWjs/evoOGh2jQeHpQSSair66+7odPeIUoOcn4Usy03Roc1N3qLiS6q8mcHaFCGMwHii3ZqUU+Ttr9R2zrYdUVOUsje8Xd67uxzcRcJwjPTdZjKvnu6UFqov3mNSlSi0mnduyS3Z9HDBYCdONR46EczeipuXPlbkTUodm4dZ4OU5Wtma/0t7xjOvBr4fC4d0+InJygpKHLo7v8AaT9xvRw+KqJPDUq0YvVKnTsvqPWpVKcacqWGhTjKF3TvvbdpW189+pyV8TXqK0q0rPfJdL22GGnAqVrYftGlNraM4uMZw5+30Zx4zsKthYSlCMq9NtZZRX1rkS8PG97XT5inUeHeejOdOXuHi/8ATxq9OXEyuNrcmVjSqZ0oXk3okj6GWJ7wvzvhn8qL0f8AhOqGCo0qLqTr5nNWjOFPb8SdV7PF7Hp15dqQp2mltV8oc7+w9P8ApLGliJVqUf8AeMIs8rc03qvZeJvhbdnReI/OyS1jKpopy5JR9mr10OKMlVjWlJX4icJS5ty/0fuLIn28rCvLhKif9opr5sb/AGnEd9b80+BzoUGpfty392a3sPPMNLQlkldG06lWairtaW+Ec501GuFF31sRZGVWDhJ318zMvOq5qz9pQAAQB0cipaT8KKmmQjc3w+HnXnaMJSST+CZ8Odr5WAgixEdEWAG9H4tmBvS+LZUW5sEDmBIFibBEVPimvI4uZ21Pi3bocsElK75BVWmlfkE3qaVLPptcrHLZ6q4EJvVW3ViXpFW36EWTZAGqqNLZbWKwdk9tTO5KdwPR7LlKWOvq3le1/sPXqKTfwZP/AAyf/IzxezLTxi8Kay7Wv9jPYqKDavGPtUftiaiVlkb3p8+cP/GTGknvThb/ANtfwyM1KP6vf+596LRq00t4fOh++gJdOml8Gl82P7qKylRS0VNP/B+BfjXWk17Jr7Kocm4P85L5z/iAeTirPFVZRyuOZtLRrfyZztcRv83eyu8jt9B1YtSeLqftu0pP7W39ZzyUL6rz2ON+Xv8Ax/xirhTtfxaa5Wltp5kRyxk2lK17q2pO2kU83usS6kYRSUFKb5y166EaUqqM6SWZ3vpcw4TRpJ+FE3udJPHj/Jy3lVsFTaxMdev1G2OqOnOKXMnAL/aH+y/rRn2n8avT7jnf5OX/ACTTxFoWLUcW8PWco+GcdpLfXc4Mze0WdCp5pSk7OOZu/Nm+y+PRp9tYin441pqS2dy2MxFSvjJzzKV3FK9rvRJfYeMrvmaZstnZSXma1Z5HoVe0q9OeGjBRSja+nw9Va/ssdk+2a8qcYOnFxum02eYtUna3RdA3qFb9odq4qq1qqatbwc/adGJr1K9K0pylorXfK2nsPPlaS6o7aUlWwFv7Sgm/2ofg/ofkQYU6k4U0k0n5kyqScXeV/aZ4iVpJO10tbdTByY0rpVacZRlF2kndNcjs4lDESUryjVcbzjB6X62tpc8nMdnZTzYtp/IZjnbni8Z66XUwiTXFd9beMhd1nPLGpKTd7eL8Dys+kW9dPvOjsyV8dBPdtpr2HO8uU+3XpHWqNHEycMPJua1eaaSS9vmbQnT7PTn3yFWTVnSg3lfq7fV7zzKlWXFcrvMnvfUtVfeKMqiSVSFs6X6S+Vb6/U68dkcbPXVXlLtCaq1qzpxs1BvWKXRfjqTQrUaVNKlNqnRi5dZSlpq+ity+9nBhal5vDyfgrLL6Pk/f9pGIccNhlQi06s9ajX6Pkb1MZyxVPuc6ai3WnJOVR7tat/Tb3HKyAZUOqq1wlqtjmN6nxS9CWt8ZrBElVuWe4YQQySAre+a1iH0JjyRooxS+Dc0ytQlUVKbTatorHdClTw/ZPGmr1ar8PkjhvZZUrK97Jl6lRzjZr3FJWJNgSQQb0vgP1MTWlOKVm7FRp7BYlTpc5P3F/wA10bKMyVFvZXNOIltBIiVWd1bReQRWVGpKLSRzvDVFul70dEqjteUvezPiRk7J3b6Ac04OFr2XtK2djetRlUaaRn3aRFZ6kXNe7TJ7tPqgOd/CWpC3OnusubHc/wC8TF0w2Jlh6qqRUW7W8R1/les/0IeyUl9pzvC5t5e5EdzttIvqOxdo1Wk8m/8AxJ/eWj2tVjooP/On95y8OKVpS1SHDp2+FH3jR2rtibVnSn/myJ/KGeGtOdv2k/sOG0Vtk+cTDTVzSit/ENE1cTB4iVS0otyutFdfQjnzxV8qj6uPka1K1KFstWcuqRzyxMv0b+1mPK6cfycpMTGb1ytLTp5FHNNJWS+00p1K2IqRpuTkpO2XqelQ7Pp4dqtUp3mvgw39rM2yHL89ny8up5EU/FFrmi1eGWpKPRnfHs2FOjSnncqlaCkktlfqbvKRyvKfavZybqtNa5dGRj3CM/Ha/Iik5YbEWekova504rBxxceLCesU20lcxynu/TN+deQ6qWyubUHKdleysHhIXtnfzfxNacMsGk9uZLZ9LbPpyOMqU3CatJcvYQpXVup6UqKxNFQbTqxsoy2sm7a+W7MJ4DJKMeLTk5SS8OpuctWcoPNGMVOMovLs1YzldWu92el2rCWek94qmoR9E9vpPNazLXqbaX1ta61NKWIVDJJScJJ3jJLb18jJq2ttOprRjhnFrE3/ALtvpM24X4VqKNR5qDi0/wBBPVfgYSU07OLR2uh2c4OUKk7r1+4o4YZ7Vqnv/Az2Z7OPxLk/ceh2Ld43VP4DMXRw7/8A6J+2R19lUaUMbFwrObs1b2Ged/8Amt8b7HmTqtpZKeWDu14fPr7jfs6qpdp07rd2VopW0fQ0hRoqmozrqdN+LLdXTt/p7jTB4WNHF05RqKp4lquW5OVnUnP1x4iMo1Z3Vlmf1k4Soo4iKnfJO8JW6NWNe1vh5I73ZxJK15Q58mdJfCujDOVF8RxtZZnK2y/HY4ZSzM6q9adalCnpGEf0Vz9epz8NlRQF+GOGwqh01Pil6GPDZrU1gl5Ga6cPtgt0S9ycjTEkVzUYDJSvsFelDCxsmmy6w1PnNr2Hqww88sX3e90reEng8uF7Mp1xy15XdYPaq/mle5zlpCcG+jdj2lg5Tjbu3ttYmHY85yVk4Lq5Dqa8V9nYuCvPDVEuTSujllGpD4dOUfVWPqF2RVhJ2qaeR00uz1HSrFNdU2Op2fGZ/I0gs0c2x9fU7F7LqpZqc4yb3iU/qx2fKDVPFVqfqlP7idavaPk4rM7bci0q7g0svtPfl/RicH+ZxsJ6845fvMv6sYi95ZH5uf4DKbHhOvOUrJpL0F5yeilI99dgVI6Xor2t/YdFPsOmleriXZcoQGVe0fNOlOStkSL0MPKMle3sPqPyX2dHTPWlLpJ2v9A/JEKjapQqQVt73L1qdnznD1tZlnCSUd/Ye5V7CxkG+A41Y775X9Jiuy8RqqiyvmrXZMpseTlq/wB4WqX1bPSl2fLlGafnEynga0X8H6B6a5FnTSbXtih4/wC781HX3DF5XKNCclHVta2RlLDV724NS/TKBz3l5e4m6S1k0/2NPrNHQq/qp/NZjUpV3pwJpfssmj1I9o0MqXi0ViV2hhXLK5JPzR4jTTs1Zm8cFiXTVVRUNHbNpc5fqjPSPQn2jgIycZyjdf3H9xHfOy57yo+2H4HhYnD13UlOdO2Z302MeBP5LJ+uH65/b6RS7Jnyw3uRKo9ly2jh/ej5vgT6MngyH6/9P1/6+nVHBJ+BU9NdJE1aNGtJubu3v4j5fhT5X9xolVb5+1Dp/qfr/wBbdoU1SxdSEVaKtb3I7sMnKjSzTn8FW8Wx5cnJvf2WLU51IPRXfS7N2eY3Z49XtLB2w0cRGUpShbNfoR2bJt2UmmlmVuZwwxE6uam5ZVKL1c3bYrh61SlJZZqPRsTjcyp1uY9udKlVrXhCEL7rInqcmLw9Og9P0tTheJxFOb/OyvfyLVsQ6lSNWfxj0ukrGJwqThYz40c/hm3aErpfssphcVGE1KcHKKd7X1K0aSztvPs1t1TRpHD0Ix8VSfplOkmN5HXWrOu8+XLFbRe66nNUjdaJuT2Rup4e7Tm23FKMrbaW/n1Ms0otShfPe6tvc1Vi3CfPfyKSorhzlrdLTR6nRVklFJPy15muMeM7NnCm4RUHFWla6btqvXyM8t+kuvLjVdOlKE6T8XN30L4dp2jkp1HyvmR0VO08QoRy8KalFN+T95nSx8pzXFioq26TMZU9/prkXPCw9k2dPZtJxx1OXAcE09c1+T5GfeKdvh/QzbAVlPH0oppp3+pjnvWrx+Y8irhp7xozj6zTOjsn83i4wmmpNq1/U1q42nG8OA3yutjPCypVO0aE4Xh4lo1uyX+K7dMe6csTVWZ5lfZebvc5ZzhwssXrzuuZbtGChj6viveTb8tTnSery3itWOM8i2erJzp01NqLi9NTq7vP5Mvcc9WTglTcLJ620+w3w2MnPEUqba8clHlzdjrEq/datr8OfzSjw8ucZe49KpUkovNiqV1o7OP3XMFJSdpVoeqsaxHFKjbe69UZyV3BHqRpQb0qw9XJfeedRWbEU05Jb6tmOU+HTh8VXI+phKOWTTPW4Uf/AFFL2s4u0KcKcoONWNRta5eRqxiONkw1kVZph8vE8TSVnuYafpdGPghpqkreRrGknHkltbMjxY9s2pRTgtlzJfbtlZR+k77HHq9zg0Xs7equSo0oyW/qoHgrt/8A4cQ+3n+rh9Je0OtfROdPLo5Nkd4SulFWatex85+Xp8oQH5dqco0/cO0Ote+q7i/DFN9SXUknaNmj5/8AL1fk4r0RD7cxHy/ch2h1r31OcHdwTt66/wA/YROanq4Xl5s+ffbeJf8AaMo+2cT+sZO0OtfQ2fKEReV34Inzj7YxX66XvKPtbFNfHS947Q619QpTtZ0180nxvan/APFHyb7SxD/tJe8q+0K7/tJe8d4dX1NSM0r8G79xy8WrGSSopLrLU+deMqt3c2/aVlWm38Jk7xer6idSclFKvKK52ikQ1RjrKtn1/SZ8txpW3NIV5LmOx1fQVcRh4xSVrpW8LZzPGUIa2m/2V9p5qxGmrNI4iLHYx6ccVhZxu80fIcbDtO0l7Wzz1XXkXVaPNxGmOzPhv0pwb5a7FXPDtt54vSyvJbHKqlN75Rmoc1AaY6J0sHVjd5VpbSST+45KnZmEkvzc3fnZWLt4bpD3kXwyd/B7x/4OKt2XJfF1E15nnVKNem2nSejtc9zPh1tk9hGfD9YmbFeA1U505fQHnlHWnUue85YfpD3FX3af6MPcZyq+dy1tlTl7zelLEQUV3e9tbvf3nqvhRfhqNfSXlUoOz0lbbMn9li5TXnQjJpuVDflpoWnCdZRU6aSjtojshiaOt4x06RLLEYd/or5okNc3dqT1bi35pm8KdKKUIulr/c+06YVcN+lbQvxsLb4EfmDE1yrDO+jptW5ItKjX1TlCa6SVzd1cI/0I/NKuWEk+a80i4a5I4OpSnxIxgne+yOCu54OveUIvd2ex7EoYe/wn7jxu1Jw4toRaUflbMlmLE0oyxk3ZabvyOrF0MRKUL1qlWKVln1Mex53jVVlo19N/uO6pVipWaZJbC315EsC9fDbUo8FLz9x6jnDnmM3Up9ZA15jwklzfuOvsihOHadCT6v8A/LN88flM7+z4U4uFRvPOTsldeFW+s5/kuca1x9rgqR7N4sk6dfNd3tLzFD8nxxFLIq+fOst5XV76Ho06NKFXiwjapd63M5YalCSmoWaknv5nm/Zx+Nrt1rxu04SnjauWO0nr1MOBUd1bc9ftBQU5VYu1pWa92v0nDxY8rnq/Hd4xy5eVhPDSm4vKo2VrLmTRwk4TjN2eXVHRnXPYmNWMdmzeM6z1WjcmZVJ2XhSZ0OtDfn6FJVo9foKjmVRP4SyrrZsupUdL1U7f3WXdaLe4lUhbkRqW/TOU6Nm4y16JGVS8op209DbiRfQzqNtaNIIwYg1m110Ft9dSIuzuZaeqsRotWRxl5nMtkDTLpVbyY7wc6YA6OO+g476GFxcDdV5FlXkc6ZeL0KNXWl1+gjiy6mdxcDTiS6jiS6mdyQjTPLTX3mbqSvv7g9tiln0YE55fKfvCnL5T95WzfItYCzk9dWXU99kn7Sr5ErzsBLdtndFVJh26kW8wNYydy+aRlTduZrmLospMspGdybjRpmJzGeYq5DUxo5ahT02RzTeu7K5vNjWpxdWbqWUlazscmbzYzsmr1dMvVFfcc7n6kcT+bl1nHVG2u2xPhitkc0amuxaVRkTGyqJPclVl1OXP5DP5DTHUqpKqLnocmbyGZl1cd9SrFRzbnDXaqfC1uQ5OxRslpjTBt0ZOz0ZvUrzcuRzRdmWbuQx0Rm5xvco5q9rJv0M41HFaJFM7zZtLgxs7fJRthqjjLJtF8jn4vki0KniWiJfhY6JTjf0ZR1ot2d7mcqivsQpxb2Rz6R07Vni5Jzer1OdNI6asouWqXuM7x+SvcbkyMX5ZuSezZXd7mt4/JXuIbj0XuNIzyvqUcX5Grl5Iq5+SAyyPoWcdCc3kiW9NiNRlYWTLN+RHsCIaVtylkaewq1oRW6ashdFL6IXKi910F/Ipcm4F7roL+hQFGmYspGVyyYF7jMytxcIvd9Rd9SlyQLX0KN+ZPIO2TXfkBFxqRddC2ZX0iBa5KZW5IEkAgDSG5rcygaXKJuTcrclMItcqxchsKznuVJluV9pGom5A9o0CoZCDt1F15hmrR3LspGSLNkRBAuRcosSUuTcC3Iqyb6EewKmxK1IJiwDIJZVsiJLQfiM7lovVCrF5PUqnqJFU9SKtU+EUuTPcoIVa6KsEMqIZVktlW/IATyKZvInNoFHYi9hfyIv5EEkMZvIjMBdbIHPxpdEONLoho6PaPac/Fl0Q40uiGo6faLrqc3Gl0Q40uiGq6rolSVjk40uiJWIkuUS6jruM3kcneJ9Ik94n0iNHXm8hm8jk7xPpEd4n0iNMdeZlXJnN3ifSJHHl0Q0x05n1Ck+rObjy6IceXRDR2KT6kp+Zx94n0Q7zPpEaY7L+YucfeZ9IjvM+kRpjug9dza/mzzFi6i5RL9+q6eGGnkNMegWR5vfqvyYe5jv1X5MPcxqY9Ihnnd/q/Jh7mO/Vfkw9zGrjsloylzkeLqPlEr3mfSI1Y7bkHH3mfSI7zPpEarrbIucneJ9IjvE+iGsuyLLnD3mfSJPeqnSJNTHY9ytzk7zPpEd5n0iXVx2qxJw95n0iT3qfSI0x3X0Iv5nF3up0iO91OkRo7rkp3ODvdTpELF1FyiNHeypx97qdIkd7qdIjTHaEtTi73U6RHe6nSJNHbJ67kHG8VN8okd5n0iFdsitjk71PpEd5n0iNHXbzIaOXvM+kR3mfRDUbso2ZceXRFeLLoho2uL6GPFl5DiPyCtRcy4j8hxH0QGgM+I/IjiPyAqACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA//2Q==\n",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"700\"\n",
       "            height=\"500\"\n",
       "            src=\"https://www.youtube.com/embed/-P28LKWTzrI\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f2bc4108b10>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('-P28LKWTzrI',  width=700, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Matrix Multiplication, CPU vs. GPU:**\n",
    "\n",
    "I wrote two programs which multiply two randomly generated matrices of specified size, \\\\(\\mathbf{A}\\\\) and \\\\(\\mathbf{B}\\\\)\n",
    "\n",
    "\\\\[\n",
    "    \\mathbf{M} = \\mathbf{A} \\times \\mathbf{B},\n",
    "\\\\]\n",
    "and timed how long it took for the programs to finish. One of these programs was written for the CPU using C++ whilst the other was written for the GPU using the CUDA programming language.\n",
    "\n",
    "**CPU:** Intel Xeon W-2145, 3.70GHz, 16 logical cores\n",
    "\n",
    "**GPU:** Titan V, 1.2 MHz, 5120 CUDA cores. This was given to us by **NVIDIA** to use in our research as part of their accelerated data science program.\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/images/CPU_vs_GPU_MatrixMult-1.png\" width=\"600\" height=\"600\" /></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turing test: How we test Artificial Intelligence\n",
    "\n",
    "Machine learning is a realisation of the pioneering work of Alan Turing in the 1950s;  where he published multiple papers, one titled \"[Computing Machinery and Intelligence](https://academic.oup.com/mind/article/LIX/236/433/986238)\". In this paper he described \"*The Imitation Game*\" as a means of answering a big question, \"**Can machines think?**\". Being practically minded Turing noted that trying to define **thinking** is a philosophical hurdle so opted for rephrasing the question as \"*Can machines do what we (as thinking entities) can do?*\" drawing a sharp distinction between the physical and intellectual capacities of a human. \n",
    "\n",
    "Turing described his version of the \"*imitation game*\", in which an interrogator attempts to distinguish which of two players is female, and where each player, hidden from sight, attempts to fool the interrogator into thinking they are the female through written answers to the interrogator’s questions. In Turing’s version, the male is replaced by a machine that attempts to respond to questions in such a way as to fool the interrogator into thinking it, not the female player, is female. \n",
    "\n",
    "The imitation game is now more commonly referred to as the **Turing test** and a subtle but vital quality of the test is that *written human language represents human-level thinking*. If the human Turing test judge is competent, then an entity requires *human-level intelligence* in order to pass the test. Modern AI systems must pass this test if they are to be deemed to have human level intelligence and as of November 2020, **nothing has passed the Turing test**, even if some have claimed to. Ray Kurzweil, Google’s director of engineering predicts that something will pass the Turing test between the years 2029 and 2040."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised vs. Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two main types of machine learning, called **supervised** and **unsupervised** learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning\n",
    "\n",
    "Consider a mathematical function of the form\n",
    "\n",
    "\\\\[\n",
    "    y = f(x).\n",
    "\\\\]\n",
    "\n",
    "Conventionally we plug in the input values \\\\(x\\\\), into the known function \\\\(f\\\\), to calculate \\\\(y\\\\). **Supervised learning** is where you have input values, \\\\(x\\\\), and an output value \\\\(y\\\\), and use an algorithm to calculate \\\\(f\\\\), the mapping function from the input to the output. **The majority of practical machine learning uses supervised learning.** The more input and output data supplied, the more accurately \\\\(f\\\\) can be defined **in theory**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to supervised learning, **unsupervised learning** is where you only have input data \\\\(x\\\\) and no corresponding output variables. The goal for unsupervised learning is to model the underlying structure or distribution in the data to learn more about it. It is phrased **unsupervised learning** as unlike supervised learning there is no correct answer and the algorithms are left to their own devises tasked with discovering and presenting interesting structure in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differences between conventional programming and machine learning\n",
    "These two types of machine learning signify the difference between traditional programming and machine learning. Conventionally we provide input data and the rules needed to transform this input data into a certain output. Supervised machine learning is supplied input data together with the related output data and attempts to figure out the rules that transform the input into the output data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning in Python: TensorFlow with a worked example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python remains one of the most popular languages for machine learning; boasting a variety of libraries aimed at its implementation including [**TensorFlow**](https://www.tensorflow.org/); an end-to-end open source machine learning platform developed by Google, available for many programming languages including Python.\n",
    "\n",
    "Most machine learning problems follow a similar implementation and solution pattern:\n",
    "\n",
    "1. Read in your data. \n",
    "2. Split the data into training and testing data.\n",
    "3. Format the data. \n",
    "4. Fit a model to the training data.\n",
    "5. Test the model on the testing data.\n",
    "\n",
    "We will learn to use TensorFlow using a simple example, **how to train a computer to recognise handwritten digits**; the \"Hello world\" of the machine learning world. First we import tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue, various parts of the code in this worksheet will flag up warnings when they are run. **These are not a concern** but are merely a product of having to get various libraries to communicate with one another. Certain Python libraries depend on specific versions of other Python libraries, so it is sometimes a balancing act to set up the environment to make them all happy. The warnings usually refer to `deprecation` statements which simply mean they are suggesting you to use newer syntax from the latest release version. A lot of programmers are tentative to update libraries as it can cause havoc with their programs; requring hours of bug fixes to chase errors caused by new syntax.\n",
    "\n",
    "**Keras** is a wrapper built on top of TensorFlow making it more accessible and easier to work with. We use it to access the [MNIST data set](http://yann.lecun.com/exdb/mnist/), composed of handwritten digits; 60,000 **training** images and 10,000 **testing** images:\n",
    "\n",
    "**Training set:** A set where we know the outcome of the feature we are modelling.\n",
    "\n",
    "**Testing set:** A set to test the model created from the training set.\n",
    "\n",
    "We load the data set using `mnist = tf.keras.datasets.mnist`. We will also print some of the images to visualise what we are going to train and test on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# load the mnist data set using keras\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# next we split the data into training and testing data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# For any pixel of the image, the value assigned to it can fall between 0 and 255. We divide by 255 to normalize the range from 0 -> 1 since this makes learning faster\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# plot the first 5 images using a loop\n",
    "for i in range(5):  \n",
    "    plt.imshow(x_train[i]) # imshow displays an image\n",
    "    plt.colorbar()         # the colorbar shows the intensity of each pixel\n",
    "    plt.show()             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Networks\n",
    "\n",
    "A neural network, more properly referred to as an 'artificial' neural network (ANN) to distinguish it from its biological counterpart, is best defined by Dr. Robert Hecht-Nielsen inventor of one of the first neurocomputers:\n",
    "\n",
    "    ...a computing system made up of a number of simple, highly interconnected processing elements, which process information by their dynamic state response to external inputs.\"\n",
    "\n",
    "As the name suggests they are inspired by biological neurons in a brain shown via the following image taken from [Machine learning algorithms in boiler plant root cause analysis ](https://www.ee.co.za/article/application-of-machine-learning-algorithms-in-boiler-plant-root-cause-analysis.html): \n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/images/neuron_node_comparison.jpeg\" width=\"600\" height=\"600\" /></center>\n",
    "\n",
    "Biological neurons are connected through synapses where information flows, corresponding to **weights** in our computational model. When we train a neural network we want the neurons to fire whenever they learn specific patterns from the data, and we model the fire rate using an **activation function**; a function attached to each neuron in the network, and determines whether it should be fired or not, based on whether each neuron's input is relevant for the model's prediction. In our biological neuron analogy: \n",
    "\n",
    "* **Synapse** strengths (weights, w, in our model) are learnable controlling the strength of influence and its direction: excitory (positive weight) or inhibitory (negative weight) of one neuron on another. \n",
    "* **Dendrites** carry the signals to the **cell body** where they are summed. If the final sum is above a certain threshold, the neuron can fire, sending a signal along its **axon**. \n",
    "* The timings of the spikes do not matter in our computational model as only the frequency of the firing communicates information. The firing rate of the neuron is modelled using an activation function (e.g sigmoid function), which represents the frequency of the signals along the axon.\n",
    "\n",
    "**How do neural networks learn?** Think about a person throwing a paper ball into a bin; the first throw provides feedback on the mass of the paper ball, air resistance, distance to the bin, force of throw etc... If they missed the bin on their first throw, the brain will change how it conducts the second throw using the information it learned from the first throw. Neural networks **learn** in exactly the same way, typically by a feedback process called **backpropagation** (\"backprop\" for short). Backpropagation involves **comparing the output a network produces with the output it was meant to produce**, and using the difference between them to modify the weights of the connections between the layers in the network, working from the output layers through the hidden layers to the input layers-going backward. Given time backpropagation causes the network to learn, reducing the difference between actual and intended output with the intention to make them coincide.\n",
    "\n",
    "Our computer model will use features of the images in the training set to learn and then make predictions on similar images that it has not seen before. We will program a basic sequential neural network with a single input, hidden and output layer; sequential meaning building up the neural network a layer at a time. Much more sophisticated models with multiple hidden layer could be used but this tutorial aims to keep it simple. We do not need to specify what patterns to look for in the images - **the neural network learns on its own**. A more computationally relevant diagram of a neural network is as follows:\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/images/neural-network-1.png\" width=\"600\" height=\"600\" /></center>\n",
    "\n",
    "We can now being programming our neural network using keras:\n",
    "\n",
    "1. Call the Sequential model from `keras.models`: \n",
    "\n",
    "    `tf.keras.models.Sequential`\n",
    "\n",
    "2. Flatten the images. This flattening process is not ideal, as we obscure information about which pixels are next to each other but this involves more complex techniques so for the purposes of this example we will flatten the images into vectors. The input layer has 784 neurons, one for each pixel in the images \\\\((28, 28) \\rightarrow 28 \\times 28 \\rightarrow 784\\\\):\n",
    "\n",
    "    `tf.keras.layers.Flatten(input_shape=(28, 28))`\n",
    "\n",
    "3. Create hidden layer with 512 nodes. 512 was chosen as a sensible value from previous experience. Choosing the number of hidden nodes is a complex topic not important for this simple example. In Keras, `Dense` usually refers to a single layer hence we are calling it here as we have a single hidden layer <font color='red'>experiment with multiple hidden layers and different activation functions!</font>:\n",
    "\n",
    "    `tf.keras.layers.Dense(512, activation=tf.nn.relu)`\n",
    "    \n",
    "    There is no \"best\" activation function and to obtain the best results requires a lot of testing. Here we are using the `relu` activation function which is simply\n",
    "\n",
    "\\\\[\n",
    "    f(x) = \\text{max}(0,x)\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(-2, 2, .1)\n",
    "zero = np.zeros(len(x))\n",
    "y = np.max([zero, x], axis=0)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_ylim([-2.0, 2.0])\n",
    "ax.set_xlim([-2.0, 2.0])\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('f(x)')\n",
    "\n",
    "ax.plot(x, y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Neural networks can suffer from overfitting to training data so to overcome this limitation we randomly selected neurons to be ignored in training. In this example we are dropping one of every five inputs for the next training cycle (0.2 = 20%). If certain neurons are turned off then other neurons need to step in to handle the portrayal of the data in each cycle, resulting in a better model and minimising the possibility of overfitting. We set the dropout rate using `keras.layers.Dropout()`:\n",
    "\n",
    "    `tf.keras.layers.Dropout(0.2)`\n",
    "\n",
    "5. We now insert another layer, the output layer with 10 neurons, one for each digit, \\\\(0 \\rightarrow 9\\\\). We will use a different activation function for this layer called the **softmax** activation function which is generally used if we need to **classify our data** which we are trying to do:\n",
    "\n",
    "    `tf.keras.layers.Dense(10, activation=tf.nn.softmax)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the neural netowrk sequentially as layers\n",
    "model = tf.keras.models.Sequential([                              # 1. specify sequential model\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),            # 2. format the images into a 2D array\n",
    "        tf.keras.layers.Dense(512, activation=tf.nn.relu),        # 3. create a densely connected neural layer with 512 nodes\n",
    "        tf.keras.layers.Dropout(0.2),                             # 4. drop 20% of the neurons each training cycle\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)       # 5. create output layer with10 nodes and use Softmax activation function\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not possible to visualise all the nodes in our model, but the following picture shows the output nodes with a greater number of input and hidden nodes, giving an insight into how neural networks scale:\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/images/neural_network-2.png\" width=\"600\" height=\"600\" /></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compile the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is Adam me? **No!**. It is not even an acronym but abbreviated from \"adaptive moment estimation\". Adam is an optimization algorithm which updates network weights based on the training data. The loss function is used to measure the variation between the value being predicted and what it actually is. **The goal is to minimize the loss (error) function.**\n",
    "\n",
    "We can now fit and evaluate our model. An **epoch** is not the same thing as an iteration, an epoch is a **complete pass of the training data**. Having a model run for too few epochs would weaken the models' performance. Having a model run for too many epochs would risk it starting to \"remember\" the outputs it may want compromising its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have achieved an accuracy of ~ 98%  with just a few lines of Python code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2181 - accuracy: 0.9353\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0989 - accuracy: 0.9697\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0698 - accuracy: 0.9779\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.0529 - accuracy: 0.9835\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0432 - accuracy: 0.9858\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0715 - accuracy: 0.9794\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0714922770857811, 0.9793999791145325]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a model, **let's test on a number which we draw!** I went to paint and drew a number 4 using the paintbrush tool and converted it into the same image format that `mnist` uses. This is important as the model learned on images which had the same normalization and size so it would not describe an image well with a completely different format! My 4 looks like this:\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/images/four_original.png\" width=\"200\" height=\"200\" /></center>\n",
    "\n",
    "after converting it into a \\\\(28 \\times 28 \\\\) pixel image:\n",
    "\n",
    "<center><img src=\"https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/images/four_converted.png\" width=\"200\" height=\"200\" /></center>\n",
    "\n",
    "We can now test our model to see if it can tell us that the number I drew is a 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f2bbc551830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "[[1.3750917e-04 7.6406002e-05 6.0026548e-03 1.0518949e-04 9.7794044e-01\n",
      "  7.9536019e-03 3.0608941e-03 4.1546491e-03 4.4301635e-04 1.2559733e-04]]\n",
      "\n",
      "Predicted digit drawn is 4 with 97.79% predicted accuracy\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "# this part of the code is only needed in Jupyter. If running locally, cv can read images from your documents without needing requests etc...\n",
    "url = r'https://raw.githubusercontent.com/adambaskerville/ProgrammingForChemists/master/images/four_converted.png'\n",
    "resp = requests.get(url, stream=True).raw\n",
    "image = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
    "image = cv.imdecode(image, cv.IMREAD_GRAYSCALE)\n",
    "\n",
    "image = image.astype('float32')\n",
    "image = image.reshape(1, 28, 28, 1)\n",
    "image = 255-image\n",
    "image /= 255\n",
    "\n",
    "# call the predict function on our image\n",
    "pred = model.predict(image.reshape(1, 28, 28), batch_size=1)\n",
    "\n",
    "# print the probability that our image is 0, 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
    "print(pred)\n",
    "\n",
    "# ask it to print its prediction\n",
    "print(\"\\nPredicted digit drawn is {} with {:.2f}% predicted accuracy\".format(pred.argmax(), pred[0, pred.argmax()]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computer has learned from training data what digits looks like and we supplied it a brand new image of the number 4, and it was able to correctly identify the number with >95% accuracy. This reveals the predictive power of DL and ML for image recognition which has so many applications to name but a few:\n",
    "\n",
    "1. Cell counting when  culturing cells.\n",
    "2. Looking for abnormalities in medical images.\n",
    "3. Augmented reality.\n",
    "4. Driverless cars.\n",
    "5. Tracking animal numbers and their migration patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worked Example: Linear Regression, Beer-Lambert law"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Linear Regression](https://mathworld.wolfram.com/LinearRegression.html) is a conventional statistical method borrowed by machine learning as a **supervised** learning algorithm where the predicted output is continuous having a constant slope. It is used to predict values such as sales or price; rather than classifying them into categories such as car or tractor. Linear regression is the simplest machine learning algorithm which a lot of you have encountered before without realising it; **finding the line of best fit.** \n",
    "\n",
    "Is this really machine learning? Lets check:\n",
    "\n",
    "* We have the input data, \\\\(x\\\\).\n",
    "* We have the output data, \\\\(y\\\\).\n",
    "* We calculate the gradient and point of intercept of a line, forming a function \\\\(f\\\\), which attempts to map \\\\(x\\\\) onto \\\\(y\\\\)  \\\\(\\hspace{0.5cm}\\therefore \\hspace{0.5cm} y = f(x) \\\\).\n",
    "\n",
    "Linear regression provides us the mapping function \\\\(f\\\\), which we can then use to predict output values we have not explicitly calculated or measured. **Machine learning is often confused with applied statistics** but linear regression can be classed as both a statistical method and a machine learning algorithm. **Lots of you have been doing machine learning without even realising it!** \n",
    "\n",
    "We are going to solve a modified version of a problem some of you encountered in Excel workshop 4 of Maths and Data Analysis for Chemists.\n",
    "\n",
    "**Question:**\n",
    "\n",
    "UV/vis spectrophotometry is often used to determine concentrations of metal ions in solution. In order to do this, knowledge of the molar extinction coefficient is needed. This is the absorbance per unit concentration at a given wavelength. A student has made a series of standard samples of KMnO\\\\(_4\\\\) of known concentrations, so as to determine the molar extinction coefficient using the Beer-Lambert law\n",
    "\n",
    "\\\\[\n",
    "    A = \\epsilon c l,\n",
    "\\\\]\n",
    "where \\\\(A\\\\) is the measured absorbance, \\\\(\\epsilon\\\\) is the molar extinction coefficient, \\\\(c\\\\) is the concentration and \\\\(l\\\\) is the path length of the spectrophotometer cell (1 cm). The spectrometer is known to suffer from a constant offset, hence the following equation should be better model the experimental data:\n",
    "\n",
    "\\\\[\n",
    "    A = \\epsilon c l + A_0,\n",
    "\\\\]\n",
    "\n",
    "Using the data, predict the absorbance when the concentration is 0.7 mM.\n",
    "\n",
    "**Solution:**\n",
    "\n",
    "This question is asking for a line of best fit to be fitted to the data set, noting that the equation of a straight line has the same form as the Beer-Lambert law\n",
    "\n",
    "\\\\[\n",
    "    \\begin{array}{cccccc}\n",
    "        & \\underbrace{A} & = & \\underbrace{\\epsilon c l} & + & \\underbrace{A_0} \\\\\n",
    "        & \\downarrow && \\downarrow && \\downarrow\\\\\n",
    "        & y & = & mx & + & c \n",
    "    \\end{array}\n",
    "\\\\] \n",
    "\n",
    "The original data set consisted of 10 data points but I have generated 200 data points for the purposes of this example, stored in `UV_vis_data.csv`. We will read this file in using pandas and fit a line of best fit to it using two techniques\n",
    "\n",
    "1. **No machine learning:** We use pandas to read in the `.csv` file and Using [`numpy.polyfit`](https://numpy.org/doc/stable/reference/generated/numpy.polyfit.html) which fits polynomials to data sets, where we specify the order of polynomial as `1`, a straight line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns # we call this library which is based on matplotlib\n",
    "\n",
    "# set a dark grid style for the plot (looks nice!)\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "# create the figure (fig) and axes (ax) objects\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# define the column names in the data file\n",
    "colnames=['concentration', 'absorbance']\n",
    "\n",
    "# read the data file into a Pandas DataFrame and assign the column names\n",
    "uv_dat = pd.read_csv(\"data/UV_vis_data.csv\", names=colnames)\n",
    "\n",
    "# use numpy to fit a line of best fit using 'polyfit'\n",
    "m, c = np.polyfit(uv_dat['concentration'], uv_dat['absorbance'], 1)\n",
    "\n",
    "# create a numpy array of x-values in order to plot the line of best fit\n",
    "x = np.arange(uv_dat['concentration'].min(),uv_dat['concentration'].max(),  0.001)\n",
    "\n",
    "# define how the y-values are calculated using the equation of a straight line\n",
    "y = m*x + c\n",
    "\n",
    "# define the axes labels\n",
    "ax.set_xlabel('Concentration / mM')\n",
    "ax.set_ylabel('Absorbance / a.u.')\n",
    "\n",
    "# plot a scatter plot\n",
    "plt.scatter(uv_dat['concentration'], uv_dat['absorbance'], s=5, color='blue');\n",
    "\n",
    "# plot the x and y-values of the line of best fit\n",
    "plt.plot(x,y)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# declare a value of x, the absorbance, for the line of best fit to use and produce a corresponding value of the concentration\n",
    "conc = 0.7\n",
    "\n",
    "# print the predicted value of concentration given an absorbance of 0.7 a.u. \n",
    "print(m*conc + c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Machine learning:** Using a linear regression machine learning algorithm from tensorflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "# define the column names in the data file\n",
    "colnames=['concentration', 'absorbance']\n",
    "\n",
    "# read the data file into a Pandas DataFrame and assign the column names\n",
    "uv_dat = pd.read_csv(\"data/UV_vis_data.csv\", names=colnames)\n",
    "\n",
    "# call the sequential model using keras\n",
    "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])])\n",
    "\n",
    "# compile the model using a mean-squared loss error and the Adam optimizer\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.keras.optimizers.Adam(learning_rate=0.1))\n",
    "\n",
    "history = model.fit(np.asarray(uv_dat['concentration']), np.asarray(uv_dat['absorbance']), epochs=20, verbose=False)\n",
    "\n",
    "# plot the loss function against epoch number\n",
    "plt.xlabel(\"Epoch Number\")\n",
    "plt.ylabel(\"Loss Magnitude\")\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()\n",
    "\n",
    "# declare a value of x, the absorbance, for the line of best fit to use and produce a corresponding value of the concentration\n",
    "conc = 0.7\n",
    "\n",
    "print(model.predict([conc]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now covered two machine learning examples and for our final example we will venture into the world of **drug discovery** and use machine learning to predict the solubility of drug molecules. First we will cover some prerequisites. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepChem: Open source machine learning for Life Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DeepChem](https://deepchem.io/) is a collection of open source tools for drug discovery, materials science, quantum chemistry, and biology; including **machine learning**. Application of machine learning to drug discovery is **very big business** [estimated to be worth \\\\$591 million in 2018](https://www.fnfresearch.com/ai-for-drug-discovery-market-by-drug-type)  and is expected to reach a value of around \\\\$12 billion by 2027.\n",
    "\n",
    "**Why?**\n",
    "\n",
    "It is estimated that bringing a new drug to market [costs major pharmaceutical companies at least \\\\$4 billion](https://www.forbes.com/sites/matthewherper/2012/02/10/the-truly-staggering-cost-of-inventing-new-drugs/#3d91a3bd4a94), and can take 10-15 years with less than 10% making it to market.\n",
    "\n",
    "Machine learning offers efficient understanding of vast amounts of chemical data, allowing for selection of the best drug candidates and predicting their possible properties; **all without even setting foot in a lab**. Drug companies like machine learning as it **can save them huge amounts of money and time.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics of DeepChem\n",
    "\n",
    "The first thing we need learn is how we can represent a wide range of complex chemical structures using a unique metric; SMILES: **S**implified **M**olecular-**I**nput **L**ine-**E**ntry **S**ystem. These take the form of a single line notation for describing the structure of chemical species using short strings. SMILES strings can be imported by most molecule editors for conversion back into two-dimensional drawings or three-dimensional models of the molecules.\n",
    "\n",
    "[SMILES](https://archive.epa.gov/med/med_archive_03/web/html/smiles.html) has the following syntax rules:\n",
    "\n",
    "1. **Atoms and Bonds:**\n",
    "\n",
    " Atoms are represented by the standard abbreviation of the chemical elements, in square brackets. A bond is represented using one of the following symbols: \n",
    "   \n",
    "| Symbol    | Meaning                 | \n",
    "|:---------:|:------------------------|\n",
    "| -         | Single bond             |   \n",
    "| =         | Double bond             |\n",
    "| #         | Triple bond             |\n",
    "| $         | Quadruple bond          |\n",
    "| :         | Aromatic bond           |\n",
    "| .         | Disconnected structures |\n",
    "\n",
    " Examples:\n",
    "    \n",
    "| SMILES      |  Chemical formula  | Name            | \n",
    "|:------------|:-------------------|:----------------|\n",
    "|  [NH4+]     | NH$_4^+$           | Ammonium        |   \n",
    "|  [OH-]      | OH$^-$             | Hydroxide anion |\n",
    "| [Na+].[Cl-] | NaCl               | Sodium chloride |\n",
    "| [OH3+]      | H$_3$O$^+$         | Hydronium cation|\n",
    "\n",
    " Combining atomic symbols and bond symbols allows for simple chain structures to be represented. The structures that are entered using SMILES are **hydrogen-suppressed**, represented without hydrogens. SMILES software understands the number of possible connections that an atom can have. \n",
    "\n",
    "| SMILES  |  Chemical formula  | Name            | \n",
    "|:--------|:-------------------|:----------------|\n",
    "|  CC     | CH$_3$CH$_3$       | Ethane          |   \n",
    "| C=C     | CH$_2$CH$_2$       | Ethene          |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <font color='red'>Experiment with this notation using the following code block which draws the structures:</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# put some molecular structures in a list\n",
    "smiles_list = [\"CC\",\"C=C\",\"[Na+].[Cl-]\"]\n",
    "\n",
    "# draw the chemical structures using MolFromSmiles\n",
    "mol_list = [Chem.MolFromSmiles(x) for x in smiles_list]\n",
    "\n",
    "# use MolsToGridImage to put the images in a grid\n",
    "img = Draw.MolsToGridImage(mol_list, molsPerRow=5, subImgSize=(250, 250), legends=None, useSVG=True)\n",
    "\n",
    "# print the structures to screen\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Branches:**\n",
    "\n",
    " A branch from a chain is specified by placing the SMILES symbol(s) for the branch between parenthesis `()`. The string in parentheses is placed directly after the symbol for the atom to which it is connected. If it is connected by a double or triple bond, the bond symbol immediately follows the left parenthesis.\n",
    "\n",
    "| SMILES            |  Name            | \n",
    "|:------------------|:-----------------|\n",
    "|  CC(O)C           | 2-Propanol       |   \n",
    "| CC(C)CC(=O)       | 2-Methylbutanal  |\n",
    "| c1c(N(=O)=O)cccc1 | Nitrobenzene     |\n",
    "\n",
    "\n",
    "4. **Rings:**\n",
    "\n",
    " SMILES allows a user to identify ring structures using numbers to identify the opening and closing ring atom. For example, in `C1CCCCC1`, the first carbon has a number '1' which connects by a single bond with the last carbon which also has a number '1'. Chemicals that have multiple rings may be identified by using different numbers for each ring. If a double, single, or aromatic bond is used for the ring closure, the bond symbol is placed before the ring closure number. Some examples:\n",
    "\n",
    "\n",
    "| SMILES         |  Name            | \n",
    "|:---------------|:-----------------|\n",
    "|  C=1CCCCC1     | Cyclohexene      |   \n",
    "| c1ccccc1       | Benzene          |\n",
    "| C1OC1CC        | Ethyloxirane     |\n",
    "| c1cc2ccccc2cc1 | Naphthalene      | \n",
    "\n",
    "5. **Charged atoms:**\n",
    "\n",
    " Charges on an atom can be used to override the knowledge regarding valence that is built into SMILES software. The format for identifying a charged atom consists of the atom followed by brackets which enclose the charge on the atom. The number of charges may be explicitly stated ({-1}) or not ({-}):\n",
    "\n",
    "| SMILES              |  Name                               | \n",
    "|:--------------------|:------------------------------------|\n",
    "|  CCC(=O)O{-1}       | Ionized form of propanoic acid      |   \n",
    "| c1ccccn{+1}1CC(=O)O | 1-Carboxylmethyl pyridinium         |\n",
    "\n",
    " <font color='red'>Pick several structures and draw them using the code box below</font>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "\n",
    "# put some molecular structures in a list\n",
    "smiles_list = []\n",
    "\n",
    "# draw the chemical structures using MolFromSmiles\n",
    "mol_list = [Chem.MolFromSmiles(x) for x in smiles_list]\n",
    "\n",
    "# use MolsToGridImage to put the images in a grid\n",
    "img = Draw.MolsToGridImage(mol_list, molsPerRow=5, subImgSize=(250, 250), legends=None, useSVG=True)\n",
    "\n",
    "# print the structures to screen\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Worked Example: Predicting the solubility of small molecules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important property of a new candidate drug is its solubility; if it isn't soluble enough then it will be unlikely to enter a patient's bloodstream to have a therapeutic effect. We will now use machine learning to build a model that predicts solubility of small molecules based on nothing but their chemical structure. We will be using the delaney dataset from [MoleculeNet](http://moleculenet.ai/datasets-1). This dataset contains structures and log-scale water solubility data for 1128 compounds: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset using deepchem\n",
    "import deepchem as dc\n",
    "\n",
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a particular kind of neural network called a **graph convolutional network**, or \"graphconv\" for short. A **graph** in machine learning is a data structure comprising of nodes (vertices) and edges connected together to represent information with no definite beginning or end. Nodes can be thought of as the atoms while the edges represent connections, the bonds.\n",
    "\n",
    "We specify `n_tasks=1` i.e. there is only one task, one output value (the solubility) for each sample. We also specify that this is a regression model, meaning that the labels are continuous numbers and the model should try to reproduce them as accurately as possible. This is in contrast to a classification model, which tries to predict which of a fixed set of classes each sample belongs to. To reduce overfitting, we specify `dropout=0.2`, meaning that 20% of the outputs from the hidden layer will randomly be set to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dc.models.GraphConvModel(n_tasks=1, mode='regression', dropout=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to train the model on the data set. We simply give it the data set and tell it how many epochs of training to perform (that is, how many complete passes through the data to make)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset, nb_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now have a fully trained model, but first we must evaluate the model on the **test set**. We do that by calling `evaluate()` on the model. For this example, we will use the **pearson correlation**, which is a number between -1 and +1 that indicates to what extent 2 variables are linearly related. We can evaluate it on both the training set and test set in order to test for overfitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, [metric], transformers))\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, [metric], transformers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is overfitting a little, but a correlation coefficient of 0.83 is respectable; so our very quick model can be said to predict the solubilities of molecules based on their molecular structures. Not too bad for just a few lines of Python code!\n",
    "\n",
    "I don't have any new molecules to hand to test our model on, so let's just use the first ten molecules from the test set. For each one we print out the chemical structure (represented as a SMILES string) and the predicted solubility. <font color='red'>If you had a molecule you could convert it into a SMILES format and test our model on it.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the solubility of 10 molecules from the test data\n",
    "solubilities = model.predict_on_batch(test_dataset.X[:10])\n",
    "\n",
    "# print the solubilities and the corresponding structure\n",
    "for molecule, solubility in zip(test_dataset.ids, solubilities):\n",
    "    print(solubility, molecule)\n",
    "\n",
    "# draw the stuctures\n",
    "mol_list = [Chem.MolFromSmiles(smiles) for smiles in test_dataset.ids[:10]]\n",
    "img = Draw.MolsToGridImage(mol_list, molsPerRow=5)\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complete solubility program:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset using deepchem\n",
    "import deepchem as dc\n",
    "\n",
    "tasks, datasets, transformers = dc.molnet.load_delaney(featurizer='GraphConv')\n",
    "train_dataset, valid_dataset, test_dataset = datasets\n",
    "\n",
    "model = dc.models.GraphConvModel(n_tasks=1, mode='regression', dropout=0.2)\n",
    "\n",
    "model.fit(train_dataset, nb_epoch=100)\n",
    "\n",
    "metric = dc.metrics.Metric(dc.metrics.pearson_r2_score)\n",
    "\n",
    "print(\"Training set score:\", model.evaluate(train_dataset, [metric], transformers))\n",
    "print(\"Test set score:\", model.evaluate(test_dataset, [metric], transformers))\n",
    "\n",
    "# predict the solubility of 10 molecules from the test data\n",
    "solubilities = model.predict_on_batch(test_dataset.X[:10])\n",
    "\n",
    "# print the solubilities and the corresponding structure\n",
    "for molecule, solubility in zip(test_dataset.ids, solubilities):\n",
    "    print(solubility, molecule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session we covered:\n",
    "\n",
    "* The difference between Artificial Intelligence (AI), Machine Learning (ML) and Deep learning (DL).\n",
    "* Hardware required for machine learning.\n",
    "* Difference between a Central Processing Unit (CPU) ans Graphics Processing Unit (GPU)\n",
    "* Doing machine learning using tensorflow in python.\n",
    "* Wrote a program to recognise hand written numerical digits.\n",
    "* Shopwed that linear regression is a machine learning algorithm.\n",
    "* Used linear regression to model the Beer-Lambert law.\n",
    "* Learned the basics of the DeepChem library and SMILES notation.\n",
    "* Wrote a program to estimate the solubility of small drug molecules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading:\n",
    "\n",
    "The DeepChem community has put together a series of tutorials on how to use DeepChem including a large variety of worked examples:\n",
    "    \n",
    "[DeepChem Tutorials](https://github.com/deepchem/deepchem/tree/master/examples/tutorials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
